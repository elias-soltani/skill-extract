{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (1.22.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (62.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.5.18.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\egha355\\AppData\\Local\\Programs\\Python\\Python39\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy_transformers\n",
      "  Downloading spacy_transformers-1.2.3-cp39-cp39-win_amd64.whl (304 kB)\n",
      "     ---------------------------------------- 304.1/304.1 kB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.5.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy_transformers) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy_transformers) (1.22.3)\n",
      "Collecting transformers<4.29.0,>=3.4.0 (from spacy_transformers)\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 10.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy_transformers) (1.11.0+cu113)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy_transformers) (2.4.6)\n",
      "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy_transformers)\n",
      "  Downloading spacy_alignments-0.9.0-cp39-cp39-win_amd64.whl (186 kB)\n",
      "     ---------------------------------------- 186.7/186.7 kB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.1.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (62.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from torch>=1.8.0->spacy_transformers) (4.2.0)\n",
      "Collecting filelock (from transformers<4.29.0,>=3.4.0->spacy_transformers)\n",
      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers<4.29.0,>=3.4.0->spacy_transformers)\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "     ---------------------------------------- 224.5/224.5 kB 6.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from transformers<4.29.0,>=3.4.0->spacy_transformers) (6.0)\n",
      "Collecting regex!=2019.12.17 (from transformers<4.29.0,>=3.4.0->spacy_transformers)\n",
      "  Downloading regex-2023.5.5-cp39-cp39-win_amd64.whl (267 kB)\n",
      "     ---------------------------------------- 268.0/268.0 kB 16.1 MB/s eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<4.29.0,>=3.4.0->spacy_transformers)\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 10.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers<4.29.0,>=3.4.0->spacy_transformers) (2023.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from packaging>=20.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (2022.5.18.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\egha355\\envs\\datascience\\lib\\site-packages (from jinja2->spacy<4.0.0,>=3.5.0->spacy_transformers) (2.1.1)\n",
      "Installing collected packages: tokenizers, spacy-alignments, regex, filelock, huggingface-hub, transformers, spacy_transformers\n",
      "Successfully installed filelock-3.12.0 huggingface-hub-0.14.1 regex-2023.5.5 spacy-alignments-0.9.0 spacy_transformers-1.2.3 tokenizers-0.13.3 transformers-4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy_transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.2'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "train_data = load_json('data/train_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "data\\training\\config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config data/training/base_config.cfg data/training/config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc(file, data):\n",
    "    nlp = spacy.blank('en')\n",
    "    db = DocBin()\n",
    "\n",
    "    for text, annotation in tqdm(data):\n",
    "        doc = nlp.make_doc(text)\n",
    "        annot = annotation['entities']\n",
    "        ents = []\n",
    "        entity_indices = []\n",
    "        for start, end, label in annot:\n",
    "            skip_entity = False\n",
    "            for idx in range(start, end):\n",
    "                if idx in entity_indices:\n",
    "                    skip_entity = True\n",
    "                    break\n",
    "            if skip_entity:\n",
    "                continue\n",
    "\n",
    "            entity_indices.extend(range(start, end))\n",
    "\n",
    "            try:\n",
    "                span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
    "            except:\n",
    "                print('Skipping entity')\n",
    "                continue\n",
    "            if span is None:\n",
    "                err_data = str([start, end])+ \"   \"+ str(text) + '\\n'\n",
    "                file.write(err_data)\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        try:\n",
    "            doc.ents = ents\n",
    "            db.add(doc)\n",
    "        except:\n",
    "            print('Skipping doc')\n",
    "            pass\n",
    "\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(train_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 60)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 29/140 [00:00<00:01, 86.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:01<00:00, 75.77it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 89.86it/s]\n"
     ]
    }
   ],
   "source": [
    "file = open('error.txt', 'w', encoding='utf-8')\n",
    "db = get_spacy_doc(file, train)\n",
    "db.to_disk('data/training/train.spacy')\n",
    "\n",
    "db = get_spacy_doc(file, test)\n",
    "db.to_disk('data/training/test.spacy')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-18 02:25:02,244] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\egha355\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\users\\egha355\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\spacy\\__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\spacy\\cli\\_util.py\", line 74, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\click\\core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\typer\\core.py\", line 778, in main\n",
      "    return _main(\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\typer\\core.py\", line 216, in _main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\click\\core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\click\\core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\click\\core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\typer\\main.py\", line 683, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\spacy\\cli\\train.py\", line 45, in train_cli\n",
      "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\spacy\\cli\\train.py\", line 67, in train\n",
      "    setup_gpu(use_gpu)\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\spacy\\cli\\_util.py\", line 581, in setup_gpu\n",
      "    require_gpu(use_gpu)\n",
      "  File \"c:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\thinc\\util.py\", line 200, in require_gpu\n",
      "    raise ValueError(\"Cannot use GPU, CuPy is not installed\")\n",
      "ValueError: Cannot use GPU, CuPy is not installed\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train data/training/config.cfg --output ./output --paths.train data/training/train.spacy --paths.dev data/training/test.spacy --gpu-id 0 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('output/model-best')\n",
    "doc = nlp('my name is Elias. I worked at Microsoft. I have experience in python, java, and c++')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1010] Unable to set entity information for token 333 which is included in more than one span in entities, blocked, missing or outside.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\egha355\\Desktop\\upgrade elias\\Job interview technical question\\Fuel50 AI engineer\\test\\test.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/egha355/Desktop/upgrade%20elias/Job%20interview%20technical%20question/Fuel50%20AI%20engineer/test/test.ipynb#Y111sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39mif\u001b[39;00m span:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/egha355/Desktop/upgrade%20elias/Job%20interview%20technical%20question/Fuel50%20AI%20engineer/test/test.ipynb#Y111sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                 ents\u001b[39m.\u001b[39mappend(span)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/egha355/Desktop/upgrade%20elias/Job%20interview%20technical%20question/Fuel50%20AI%20engineer/test/test.ipynb#Y111sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     doc\u001b[39m.\u001b[39ments \u001b[39m=\u001b[39m ents\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/egha355/Desktop/upgrade%20elias/Job%20interview%20technical%20question/Fuel50%20AI%20engineer/test/test.ipynb#Y111sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     db\u001b[39m.\u001b[39madd(doc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/egha355/Desktop/upgrade%20elias/Job%20interview%20technical%20question/Fuel50%20AI%20engineer/test/test.ipynb#Y111sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m db\u001b[39m.\u001b[39mto_disk(\u001b[39m\"\u001b[39m\u001b[39m./train.spacy\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\spacy\\tokens\\doc.pyx:760\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.ents.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\spacy\\tokens\\doc.pyx:797\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E1010] Unable to set entity information for token 333 which is included in more than one span in entities, blocked, missing or outside."
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "# the DocBin will store the example documents\n",
    "db = DocBin()\n",
    "for text, annotations in train_data:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations['entities']:\n",
    "        if label == 'Skills':\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span:\n",
    "                ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./train.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=2, step=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobpost</th>\n",
       "      <th>date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>AnnouncementCode</th>\n",
       "      <th>Term</th>\n",
       "      <th>Eligibility</th>\n",
       "      <th>Audience</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>Duration</th>\n",
       "      <th>...</th>\n",
       "      <th>Salary</th>\n",
       "      <th>ApplicationP</th>\n",
       "      <th>OpeningDate</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Notes</th>\n",
       "      <th>AboutC</th>\n",
       "      <th>Attach</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>IT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMERIA Investment Consulting Company\\r\\nJOB TI...</td>\n",
       "      <td>Jan 5, 2004</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>AMERIA Investment Consulting Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To apply for this position, please submit a\\r\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26 January 2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             jobpost         date  \\\n",
       "0  AMERIA Investment Consulting Company\\r\\nJOB TI...  Jan 5, 2004   \n",
       "\n",
       "                     Title                               Company  \\\n",
       "0  Chief Financial Officer  AMERIA Investment Consulting Company   \n",
       "\n",
       "  AnnouncementCode Term Eligibility Audience StartDate Duration  ... Salary  \\\n",
       "0              NaN  NaN         NaN      NaN       NaN      NaN  ...    NaN   \n",
       "\n",
       "                                        ApplicationP OpeningDate  \\\n",
       "0  To apply for this position, please submit a\\r\\...         NaN   \n",
       "\n",
       "          Deadline Notes AboutC Attach  Year Month     IT  \n",
       "0  26 January 2004   NaN    NaN    NaN  2004     1  False  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8636"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Title\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['jobpost', 'date', 'Title', 'Company', 'AnnouncementCode', 'Term',\n",
       "       'Eligibility', 'Audience', 'StartDate', 'Duration', 'Location',\n",
       "       'JobDescription', 'JobRequirment', 'RequiredQual', 'Salary',\n",
       "       'ApplicationP', 'OpeningDate', 'Deadline', 'Notes', 'AboutC', 'Attach',\n",
       "       'Year', 'Month', 'IT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accountant                  328\n",
       "Chief Accountant            219\n",
       "Medical Representative      216\n",
       "Sales Manager               166\n",
       "Administrative Assistant    155\n",
       "Lawyer                      151\n",
       "Software Developer          134\n",
       "Project Manager             117\n",
       "English Language Courses    109\n",
       "Web Developer               101\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Title\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobpost</th>\n",
       "      <th>date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>AnnouncementCode</th>\n",
       "      <th>Term</th>\n",
       "      <th>Eligibility</th>\n",
       "      <th>Audience</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>Duration</th>\n",
       "      <th>...</th>\n",
       "      <th>Salary</th>\n",
       "      <th>ApplicationP</th>\n",
       "      <th>OpeningDate</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Notes</th>\n",
       "      <th>AboutC</th>\n",
       "      <th>Attach</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>IT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18999</th>\n",
       "      <td>San Lazzaro   LLC\\r\\n\\r\\n\\r\\nTITLE:  Head of O...</td>\n",
       "      <td>Dec 30, 2015</td>\n",
       "      <td>Head of Online Sales Department</td>\n",
       "      <td>San Lazzaro   LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Long-term</td>\n",
       "      <td>...</td>\n",
       "      <td>Highly competitive</td>\n",
       "      <td>Interested candidates can send their CVs to:\\r...</td>\n",
       "      <td>30 December 2015</td>\n",
       "      <td>29 January 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Lazzaro LLC works with several internation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19000</th>\n",
       "      <td>\"Kamurj\" UCO CJSC\\r\\n\\r\\n\\r\\nTITLE:  Lawyer in...</td>\n",
       "      <td>Dec 30, 2015</td>\n",
       "      <td>Lawyer in Legal Department</td>\n",
       "      <td>\"Kamurj\" UCO CJSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indefinite</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All qualified applicants are encouraged to\\r\\n...</td>\n",
       "      <td>30 December 2015</td>\n",
       "      <td>20 January 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Kamurj\" UCO CJSC is providing micro and small...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 jobpost          date  \\\n",
       "18999  San Lazzaro   LLC\\r\\n\\r\\n\\r\\nTITLE:  Head of O...  Dec 30, 2015   \n",
       "19000  \"Kamurj\" UCO CJSC\\r\\n\\r\\n\\r\\nTITLE:  Lawyer in...  Dec 30, 2015   \n",
       "\n",
       "                                 Title            Company AnnouncementCode  \\\n",
       "18999  Head of Online Sales Department  San Lazzaro   LLC              NaN   \n",
       "19000       Lawyer in Legal Department  \"Kamurj\" UCO CJSC              NaN   \n",
       "\n",
       "            Term Eligibility Audience StartDate    Duration  ...  \\\n",
       "18999        NaN         NaN      NaN       NaN   Long-term  ...   \n",
       "19000  Full-time         NaN      NaN       NaN  Indefinite  ...   \n",
       "\n",
       "                   Salary                                       ApplicationP  \\\n",
       "18999  Highly competitive  Interested candidates can send their CVs to:\\r...   \n",
       "19000                 NaN  All qualified applicants are encouraged to\\r\\n...   \n",
       "\n",
       "            OpeningDate         Deadline Notes  \\\n",
       "18999  30 December 2015  29 January 2016   NaN   \n",
       "19000  30 December 2015  20 January 2016   NaN   \n",
       "\n",
       "                                                  AboutC Attach  Year Month  \\\n",
       "18999  San Lazzaro LLC works with several internation...    NaN  2015    12   \n",
       "19000  \"Kamurj\" UCO CJSC is providing micro and small...    NaN  2015    12   \n",
       "\n",
       "          IT  \n",
       "18999  False  \n",
       "19000  False  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMERIA Investment Consulting Company\n",
      "JOB TITLE:  Chief Financial Officer\n",
      "POSITION LOCATION: Yerevan, Armenia\n",
      "JOB DESCRIPTION:   AMERIA Investment Consulting Company is seeking a\n",
      "Chief Financial Officer. This position manages the company's fiscal and\n",
      "administrative functions, provides highly responsible and technically\n",
      "complex staff assistance to the Executive Director. The work performed\n",
      "requires a high level of technical proficiency in financial management\n",
      "and investment management, as well as management, supervisory, and\n",
      "administrative skills.\n",
      "JOB RESPONSIBILITIES:  \n",
      "- Supervises financial management and administrative staff, including\n",
      "assigning responsibilities, reviewing employees' work processes and\n",
      "products, counseling employees, giving performance evaluations, and\n",
      "recommending disciplinary action;\n",
      "- Serves as member of management team participating in both strategic\n",
      "and operational planning for the company;\n",
      "- Directs and oversees the company's financial management activities,\n",
      "including establishing and monitoring internal controls, managing cash\n",
      "and investments, and managing the investment portfolio in collaboration\n",
      "with the Investment team leader. This includes, but is not limited to,\n",
      "evaluation of investment risk, concentration risk, fund deployment\n",
      "levels, adequacy of loss and liquidity reserves Assists investment team\n",
      "in development of proper documentation and internal systems;\n",
      "- Directs and oversees the annual budgeting process, including\n",
      "developing projections for financial planning, and preparing budgets;\n",
      "- Prepares external and internal financial management reports, such as\n",
      "audited financial statements, tax returns, and reports for the board of\n",
      "directors and company staff;\n",
      "- Develops, implements, and maintains efficient and effective accounting\n",
      "systems and controls to ensure compliance with national and\n",
      "international accounting standards and principles, sufficiency of fund\n",
      "accounting, and comprehensiveness of data for reporting and compliance\n",
      "requirements;\n",
      "- Ensures contract compliance, including interpreting and monitoring\n",
      "contracts with clients, submitting required reports, and monitoring\n",
      "covenants and other contract terms;\n",
      "- Oversees the design, implementation and maintenance of computer-based\n",
      "information system. Oversees records retention (both manual and\n",
      "computer-based) and file maintenance activities;\n",
      "- Serves as company's risk manager, including evaluating loss exposure\n",
      "and obtaining insurance as appropriate;\n",
      "- Manages other administrative operations, such as facilities\n",
      "management, payroll administration, office operations, and\n",
      "administrative support;\n",
      "- Monitors corporate compliance with by-laws and articles of\n",
      "incorporation regarding corporate registration and reporting of\n",
      "fundraising operations.\n",
      "REQUIRED QUALIFICATIONS:  To perform this job successfully, an\n",
      "individual must be able to perform each essential duty satisfactorily.\n",
      "The requirements listed below are representative of the knowledge,\n",
      "skill, and/or ability required.\n",
      "Knowledge of:\n",
      "- Generally accepted accounting principles;\n",
      "- Local accounting standards and legislation;\n",
      "- State reporting requirements pertaining to accounting;\n",
      "- Principles and practices of financial management and budgeting;\n",
      "- Principles and practices of financial systems design and analysis;\n",
      "- Principles and practices of contract management, records management,\n",
      "and risk management;\n",
      "- Principles and practices of management and supervision;\n",
      "- Principles and practices of information systems management.\n",
      "Ability to:\n",
      "- Apply sound fiscal and administrative practices to the company's\n",
      "activities;\n",
      "- Plan, organize and supervise the work of subordinate employees,\n",
      "including training them, assigning and evaluating their work, and\n",
      "providing job performance feedback;\n",
      "- Critically analyze fiscal and administrative policies, practices,\n",
      "procedures, and systems, and recommend and implement changes as needed;\n",
      "- Gather and synthesize financial information from a variety of sources\n",
      "and present it to a variety of audiences with differing financial\n",
      "management and analysis expertise;\n",
      "- Prepare detailed, comprehensive financial reports, including\n",
      "explanatory text;\n",
      "- Operate IBM-compatible personal computer, including word processing,\n",
      "spreadsheet, and database software applications;\n",
      "- Operate specialized software applications that support the financial\n",
      "management and budgeting functions.\n",
      "Qualifications:\n",
      "- A minimum of 5-7 years Accounting/ Corporate Finance/ Banking\n",
      "experience, including a role as a CFO;\n",
      "- Excellent finance and accounting technical skills coupled with a\n",
      "demonstrated knowledge of all key financial functions in an consulting\n",
      "company context - accounting, finance, control, treasury, reserving, and\n",
      "reporting;\n",
      "- Strong financial planning and analytical skills and experience and the\n",
      "ability to work closely with and support the CEO and other executives in\n",
      "strategic development and implementation;\n",
      "- Excellent leadership, management and supervisory track record of\n",
      "attracting, selecting, developing, rewarding and retaining high-caliber,\n",
      "accounting and finance executive and teams who achieve business goals;\n",
      "- An undergraduate degree in finance, business, or other related\n",
      "discipline is required. A CPA, CFA, ACCA or other financial\n",
      "certification is highly preferred, as is a Masters degree in Business\n",
      "Administration, Accounting or Finance;\n",
      "- Fluency in English, Armenian and Russian with outstanding writing\n",
      "skills;\n",
      "- Excellent analytical, communication, teamwork, interpersonal skills;\n",
      "- Need to be well organized and detail-oriented as well as goal/ result\n",
      "driven and able to deal with complex issues.\n",
      "APPLICATION PROCEDURES:  To apply for this position, please submit a\n",
      "cover letter and a resume addressing relevant qualifications and\n",
      "experience and information on professional reference strictly to Tatevik\n",
      "Hovhannisyan; Executive Assistant: fax: 374-1-546800 or e-mail:ameria@.... Tel: 374 (1) 524040; 524140. Only shortlisted\n",
      "candidates will be notified for an interview.\n",
      "Please clearly mention in your application letter that you learned of\n",
      "this job opportunity through Career Center and mention the URL of its\n",
      "website - www.careercenter.am, Thanks.\n",
      "APPLICATION DEADLINE:   26 January 2004\n",
      "----------------------------------\n",
      "To place a free posting for job or other career related opportunities in\n",
      "your organization at careercenter.am website, e-mail us atmailbox@...\n"
     ]
    }
   ],
   "source": [
    "print(df['jobpost'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yerevan, Armenia                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              17061\n",
       "Gyumri, Armenia                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 102\n",
       "Abovyan, Armenia                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 95\n",
       "Tbilisi, Georgia                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 74\n",
       "Vanadzor, Armenia                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                72\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ...  \n",
       "Yerevan, Armenia\\r\\nDETAIL DESCRIPTION:  The Junior Faculty Development Program (JFDP) is\\r\\nmanaged and funded by the Bureau of Educational and Cultural Affairs of\\r\\nthe United States Department of State (ECA) and administered by the\\r\\nAmerican Councils for International Education: ACTR/ACCELS, an American\\r\\nnon-profit, non governmental organization. The United States Congress\\r\\nannually appropriates funds to finance the JFDP, and authorizes the\\r\\nBureau of Educational and Cultural Affairs to oversee these funds.\\r\\nThe primary and distinct goal of the JFDP is to provide university\\r\\ninstructors from Albania, Armenia, Azerbaijan, Bosnia and Herzegovina,\\r\\nCroatia, Georgia, Kazakhstan, Kyrgyzstan, Macedonia, Montenegro, Serbia,\\r\\nTajikistan, Turkmenistan, and residents of Kosovo with training in the\\r\\nfields of Humanities and Social Sciences. \\r\\nParticipants in the JFDP are also encouraged to forge relationships\\r\\nbetween U.S. universities and their home university, in order to support\\r\\nongoing contact and collaboration. JFDP fellows will: \\r\\n- work closely with faculty mentors from host universities in the United\\r\\nStates to advance their academic knowledge;\\r\\n- gather new academic materials and resources;\\r\\n- garner new educational perspective; and \\r\\n- enlighten U.S. faculty and students on education and life in their\\r\\nhome countries. \\r\\nThroughout their stay in the United States, JFDP Fellows observe and\\r\\nlisten to courses, attend academic conferences, and may be invited to\\r\\nteach or co-teach classes at a U.S. university. Fellows do not earn\\r\\nacademic degrees, credits or transcripts through the JFDP, and must\\r\\nreturn to their home countries after completing the program.\\r\\nEach JFDP Fellow will spend a total of five (5) months (January-May\\r\\n2008) in the United States. American Councils is responsible for placing\\r\\nFellows at U.S. host universities and for providing logistical support\\r\\nfor the Fellows throughout their stay in the United States. The JFDP\\r\\nFellowship provides round-trip international and domestic\\r\\ntransportation, medical insurance, monthly stipends, and professional\\r\\ndevelopment funds. In addition, ECA and American Councils sponsor events\\r\\nand activities for JFDP alumni after they return to their home\\r\\ncountries.\\r\\nMore detailed information about the program requirements is available at\\r\\nthe American Councils office in Armenia at: 1 Bagramian Ave., apt. 1,\\r\\ne-mail: nane@..., tel: 56 00 45, 54 40 12, 54 40 15.\\r\\nREQUIREMENTS:  To qualify for a JFDP Fellowship, an applicant must:\\r\\n- hold a university degree;\\r\\n- be currently teaching at an institution of higher education;\\r\\n- have at least two years of teaching experience at an institution of\\r\\nhigher education;\\r\\n- have a mastery of the English language.        1\n",
       "Vayots Dzor Marz, Armenia                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
       "Yerevan, Armenia\\r\\nDETAIL DESCRIPTION:  European Carolus Magnus University (Belgium) in\\r\\nassociation with the Branch of European Economic Chamber of Trade,\\r\\nCommerce and Industry, EEIG for Armenia announces admission to its\\r\\nMasters' leading educational program  Master of Business Administration\\r\\n(MBA). \\r\\nThe studies are conducted in accordance with Belgian Carolus Magnus\\r\\nUniversity educational program and curriculum. Duration of the program\\r\\nis two years, with classes held three times a week in evening hours.\\r\\nStudies are held in English language.\\r\\nThe program is chargeable. All the documents for admission and teaching\\r\\nmaterials are provided to the students free of charge.\\r\\nAfter graduation in two years you will not only have up-to-date\\r\\nknowledge, but also an MBA diploma from Belgian Carolus Magnus\\r\\nUniversity which will open for you all the doors in the world. \\r\\nInformative seminars on the University are being organized by the\\r\\ncompany for all the interested persons, free of charge.\\r\\nEDUCATIONAL LEVEL:  Postgraduate\\r\\nREQUIREMENTS:\\r\\n- Undergraduates of accredited higher educational institutions can\\r\\napply;\\r\\n- Knowledge of English language.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
       "Yerevan, Armenia\\r\\nDETAIL DESCRIPTION:  The training on Strategic Public Relations will\\r\\nprovide you with a basic understanding of public relations processes,\\r\\npractices, and effects. The course is focused toward public relations as\\r\\na career, but will also provide you the opportunity to develop an\\r\\nunderstanding of the ways in which public relation decision affect a\\r\\nwide range of occupations. \\r\\nThis course will help you to learn the critical thinking processes\\r\\ninvolved in solving organizational problems and making public relations\\r\\ndecisions. You will also have an opportunity to explore some issues\\r\\nfacing public relations practitioners in today's increasingly\\r\\ntechnological, multicultural, and global environment.\\r\\nMost of the lessons will be accompanied with relevant examples. The\\r\\nparticipants of the training will be expected to point out to problems\\r\\nand propose scenarios of possible solutions.   \\r\\nThe course fee is 100,000 AMD (including VAT).\\r\\nPlease be advised that the course will be taught in English language.\\r\\nTopics/Lessons:\\r\\n- History of informing and persuading: PR from the dawn of\\r\\ncivilization;\\r\\n- Public relations and communications;\\r\\n- The role of PR in management and its contribution to organizational\\r\\neffectiveness; \\r\\n- Prioritizing stakeholders for PR;\\r\\n- Strategic communications to support organizations objectives (PR);\\r\\n- Stages of behavior change; precontemplation stage;\\r\\n- Contemplation stage;\\r\\n- Bringing social influence to bear and enhancing self-control;\\r\\n- Inducing action and ensuring maintenance;\\r\\n- PR and the law. Media-related legal and institutional framework of\\r\\nArmenia;\\r\\n- Principles of media relations;\\r\\n- Fundamentals of good PR writing;\\r\\n- Corporate social responsibility (CSR);\\r\\n- Media coverage of promo events vs media coverage of charity or CSR\\r\\nevents;\\r\\n- PR and the internet;\\r\\n- Electronic media and press in Armenia;\\r\\n- Effective internal communication;\\r\\n- PR in politics and government;\\r\\n- Events organization;\\r\\n- Reputation management: measuring, valuing and changing reputation;\\r\\n- Global news networks in the information market;\\r\\n- Organization of Press conferences and briefings;\\r\\n- Techniques of shooting and editing;\\r\\n- How TV companies work  Agenda setting  walk through TV company;\\r\\n- Interview.\\r\\nAfter successfully completing the course, every participant will receive\\r\\na Course Completion Certificate.\\r\\nREQUIREMENTS:  N/A                                                                                                                                                                                                                                                                                                                                              1\n",
       "Alaverdi, Lori Marz, Armenia                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
       "Name: Location, Length: 759, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "The data location is mostly for Armenia and Georgia. But the roles are diverse and the structure of the job description is good for the machine learning.\n",
    "For the purpose of this task, to make the code run faster I will try a subset of the data with 300 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jobpost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>T Lab\\r\\nTITLE:  iOS Developer\\r\\nTERM:  Full ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SAS Group LLC\\r\\nTITLE:  C++ Programmer\\r\\nDUR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            jobpost\n",
       "0   1  T Lab\\r\\nTITLE:  iOS Developer\\r\\nTERM:  Full ...\n",
       "1   2  SAS Group LLC\\r\\nTITLE:  C++ Programmer\\r\\nDUR..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=300, random_state=42, ignore_index=True)\n",
    "df = df[['jobpost']]\n",
    "df['id'] = df.index + 1\n",
    "df = df[['id', 'jobpost']]\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "We do preprocessing by removing stopwords, email, or numbers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the first job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T Lab\\r\\nTITLE:  iOS Developer\\r\\nTERM:  Full time\\r\\nSTART DATE/ TIME:  Immediately\\r\\nDURATION:  Long term\\r\\nLOCATION:  Yerevan, Armenia\\r\\nJOB DESCRIPTION:  T. Lab is looking for a hardworking individual to fill\\r\\nthe position of iOS Developer. The successful candidate will apply\\r\\nexperience with mobile technology/ solutions and business operations of\\r\\nstart-ups.\\r\\nJOB RESPONSIBILITIES:\\r\\n- Architect, build and manage set of iOS applications;\\r\\n- Work with team members on server-side integration;\\r\\n- Work with Designers to help define and implement User Interface\\r\\nimprovements;\\r\\n- Work with customer teams to understand requirements and expectations;\\r\\n- Implement conversion experiments (A/ B tests);\\r\\n- Participate in task estimates;\\r\\n- Ensure high quality in deliverables.\\r\\nREQUIRED QUALIFICATIONS:\\r\\n- Passion for social innovation and new technology tools;\\r\\n- Experience in iOS application development using iOS SDK;\\r\\n- Strong foundation in Objective-C and Xcode;\\r\\n- Knowledge of Object Oriented concepts;\\r\\n- Good understanding of best practices for mobile UI/ UX;\\r\\n- Excellent attention to detail;\\r\\n- Good knowledge of English language, both written and spoken.\\r\\nAPPLICATION PROCEDURES:  Those who meet above listed requirements and\\r\\nqualifications, are asked to send their application letters and CVs to:hr@... .\\r\\nPlease clearly mention in your application letter that you learned of\\r\\nthis job opportunity through Career Center and mention the URL of its\\r\\nwebsite - www.careercenter.am, Thanks.\\r\\nOPENING DATE:  21 November 2014\\r\\nAPPLICATION DEADLINE:  20 December 2014\\r\\nABOUT COMPANY:  T. Lab is a newly established software lab of Telasco\\r\\nGroup, represented in Yerevan by Armenian Representative Office of\\r\\nTelasco Communications.\\r\\n----------------------------------\\r\\nTo place a free posting for job or other career-related opportunities\\r\\navailable in your organization, just go to the www.careercenter.am\\r\\nwebsite and follow the \"Post an Announcement\" link.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['jobpost'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove punctuations, stop words and non-alphabetic characters. We should note that some skills such as C++,C#, .NET, Vue.js will not be extracted.\n",
    "One way to fix this is to create spacial tokens for them in spaCy. Knowing this, we continue with the preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.ner.EntityRecognizer object at 0x00000272D1C24660> (name: 'skill_ner').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\egha355\\Desktop\\upgrade elias\\Job interview technical question\\Fuel50 AI engineer\\test\\test.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/egha355/Desktop/upgrade%20elias/Job%20interview%20technical%20question/Fuel50%20AI%20engineer/test/test.ipynb#Y106sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ner \u001b[39m=\u001b[39m nlp\u001b[39m.\u001b[39mcreate_pipe(\u001b[39m\"\u001b[39m\u001b[39mner\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/egha355/Desktop/upgrade%20elias/Job%20interview%20technical%20question/Fuel50%20AI%20engineer/test/test.ipynb#Y106sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ner\u001b[39m.\u001b[39madd_label(\u001b[39m\"\u001b[39m\u001b[39mSKILL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/egha355/Desktop/upgrade%20elias/Job%20interview%20technical%20question/Fuel50%20AI%20engineer/test/test.ipynb#Y106sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m nlp\u001b[39m.\u001b[39;49madd_pipe(ner, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mskill_ner\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/egha355/Desktop/upgrade%20elias/Job%20interview%20technical%20question/Fuel50%20AI%20engineer/test/test.ipynb#Y106sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m nlp\u001b[39m.\u001b[39mto_disk(\u001b[39m\"\u001b[39m\u001b[39mskill_model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\egha355\\Envs\\datascience\\lib\\site-packages\\spacy\\language.py:772\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    770\u001b[0m     bad_val \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39m(factory_name)\n\u001b[0;32m    771\u001b[0m     err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE966\u001b[39m.\u001b[39mformat(component\u001b[39m=\u001b[39mbad_val, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 772\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    773\u001b[0m name \u001b[39m=\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m factory_name\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponent_names:\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.ner.EntityRecognizer object at 0x00000272D1C24660> (name: 'skill_ner').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "# cleaning the data\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "ner.add_label(\"SKILL\")\n",
    "nlp.add_pipe(ner, name=\"skill_ner\")\n",
    "nlp.to_disk(\"skill_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "class TrainDataGenerator:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.entities = []\n",
    "\n",
    "    def add_entity(self, searchTerm = '', entity_name=''):\n",
    "        try:\n",
    "            response = re.search(searchTerm, self.text)\n",
    "            data_entity = (response.start(), response.end(), entity_name)\n",
    "            self.entities.append(data_entity)\n",
    "        except Exception as e:pass\n",
    "\n",
    "    def complete_entity(self):\n",
    "\n",
    "        entity_tem = {\"entities\":self.entities}\n",
    "        data = (self.text, entity_tem)\n",
    "\n",
    "        entities = entity_tem.get(\"entities\")\n",
    "\n",
    "        # check if entity first index is overlapping with another one\n",
    "        for i in range(0, len(entities)):\n",
    "            for j in range(i+1, len(entities)):\n",
    "\n",
    "\n",
    "                StartIndex1 = entities[i][0]\n",
    "                endIndex1 = entities[i][1]\n",
    "\n",
    "                StartIndex2 = entities[j][0]\n",
    "                endIndex2 = entities[j][1]\n",
    "\n",
    "                if StartIndex1 in range(StartIndex2, endIndex2):\n",
    "                    return False\n",
    "                if endIndex2 in range(StartIndex2, endIndex2):\n",
    "                    return False\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read job postings csv file and create data pipeline. remove header, and newline characters, normalize data, tokenize the text, and remove stop words, punctuation, and numbers,\n",
    "# and lemmatize the text. transform text data into a format suitable for machine learning using word embeddings. You can use spaCy, NLTK, scikit-learning, or any other library\n",
    "def read_data(file_path):\n",
    "    data = pd.read_csv(file_path, header=None, names=['job_title', 'job_description'])\n",
    "    data['job_description'] = data['job_description'].str.replace('\\n', ' ')\n",
    "    data['job_description'] = data['job_description'].str.replace('\\r', ' ')\n",
    "    data['job_description'] = data['job_description'].str.replace('\\t', ' ')\n",
    "    data['job_description'] = data['job_description'].str.replace('\\xa0', ' ')\n",
    "    data['job_description'] = data['job_description'].str.replace('\\u200b', ' ')\n",
    "    data['job_description'] = data['job_description'].str.replace('\\u200c', ' ')\n",
    "    data['job_description'] = data['job_description'].str.replace('\\u200d', ' ')\n",
    "\n",
    "    return data\n",
    "\n",
    "# normalize data\n",
    "def normalize_data(data):\n",
    "    data['job_description'] = data['job_description'].str.lower()\n",
    "    data['job_description'] = data['job_description'].str.replace(r'\\d+','')\n",
    "    data['job_description'] = data['job_description'].str.replace(r'\\W',' ')\n",
    "    data['job_description'] = data['job_description'].str.replace(r'\\s+',' ')\n",
    "    data['job_description'] = data['job_description'].str.strip()\n",
    "\n",
    "    return data\n",
    "\n",
    "# tokenize the text using the libraries mentioned above\n",
    "def tokenize_text(data):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    data['job_description'] = data['job_description'].apply(lambda x: nlp(x))\n",
    "    data['job_description'] = data['job_description'].apply(lambda x: [token.lemma_ for token in x if not token.is_stop and not token.is_punct and not token.is_digit and not token.is_space])\n",
    "\n",
    "    return data\n",
    "\n",
    "# normalize the remaining dat to their base form using lemmatization. use the libraries mentioned above\n",
    "def lemmatize_text(data):\n",
    "    data['job_description'] = data['job_description'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    return data\n",
    "\n",
    "# transform text data into a format suitable for machine learning using word embeddings. use the libraries mentioned above\n",
    "data = read_data('job_postings.csv')\n",
    "data = normalize_data(data)\n",
    "data = tokenize_text(data)\n",
    "data = lemmatize_text(data)\n",
    "\n",
    "\n",
    "# Machine learning model\n",
    "# we want to extract the skills from the job description. we will use the job title as the label for the job description. we will use the libraries mentioned above to train a machine learning model\n",
    "# we can use spaCY, NLTK, scikit-learn, tensorflow or any other library\n",
    "# the model should take in the transformed text data from the data pipeline and generate a list of skills that are mentioned in the text (job description).\n",
    "\n",
    "# train the model\n",
    "def train_model(data):\n",
    "    TRAIN_DATA = []\n",
    "    for index, row in data.iterrows():\n",
    "        TRAIN_DATA.append((row['job_description'], {'entities': [(0, len(row['job_title']), 'JOB_TITLE')]}))\n",
    "\n",
    "    nlp = spacy.blank('en')\n",
    "    nlp.vocab.vectors.name = 'spacy_pretrained_vectors'\n",
    "    optimizer = nlp.begin_training()\n",
    "\n",
    "    for itn in range(10):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "        print('Losses', losses)\n",
    "\n",
    "    return nlp\n",
    "\n",
    "# test the model\n",
    "def test_model(nlp, data):\n",
    "    data['job_description'] = data['job_description'].apply(lambda x: nlp(x))\n",
    "    data['job_description'] = data['job_description'].apply(lambda x: [token.lemma_ for token in x if not token.is_stop and not token.is_punct and not token.is_digit and not token.is_space])\n",
    "    data['job_description'] = data['job_description'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    return data\n",
    "\n",
    "# evaluate the model\n",
    "def evaluate_model(nlp, data):\n",
    "    data['job_description'] = data['job_description'].apply(lambda x: nlp(x))\n",
    "    data['job_description'] = data['job_description'].apply(lambda x: [token.lemma_ for token in x if not token.is_stop and not token.is_punct and not token.is_digit and not token.is_space])\n",
    "    data['job_description'] = data['job_description'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    return data\n",
    "\n",
    "# save the model\n",
    "def save_model(nlp, output_dir):\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.meta['name'] = 'job_title'\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "# load the model\n",
    "def load_model(input_dir):\n",
    "    input_dir = Path(input_dir)\n",
    "    nlp = spacy.load(input_dir)\n",
    "    print(\"Loaded model from\", input_dir)\n",
    "\n",
    "    return nlp\n",
    "\n",
    "# predict the skills from the job description\n",
    "nlp = train_model(data)\n",
    "data = test_model(nlp, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_df corresponds to < documents than min_df",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m      2\u001b[0m cv\u001b[38;5;241m=\u001b[39mCountVectorizer(max_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.50\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m word_count_vector\u001b[38;5;241m=\u001b[39m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfTransformer\n\u001b[0;32m      6\u001b[0m tfidf_transformer\u001b[38;5;241m=\u001b[39mTfidfTransformer(smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Envs\\datascience\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1352\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1348\u001b[0m min_doc_count \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1349\u001b[0m     min_df \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(min_df, numbers\u001b[38;5;241m.\u001b[39mIntegral) \u001b[38;5;28;01melse\u001b[39;00m min_df \u001b[38;5;241m*\u001b[39m n_doc\n\u001b[0;32m   1350\u001b[0m )\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_doc_count \u001b[38;5;241m<\u001b[39m min_doc_count:\n\u001b[1;32m-> 1352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_df corresponds to < documents than min_df\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1354\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_features(X, vocabulary)\n",
      "\u001b[1;31mValueError\u001b[0m: max_df corresponds to < documents than min_df"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"\"\"About the job Fuel50 is a cloud-based SaaS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"\"\"About the job Fuel50 is a cloud-based SaaS ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   1  \"\"\"About the job Fuel50 is a cloud-based SaaS ...\n",
       "1   2  \"\"\"About the job Fuel50 is a cloud-based SaaS ..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "import json\n",
    "\n",
    "with open(\"exercises/en/countries.json\", encoding=\"utf8\") as f:\n",
    "    COUNTRIES = json.loads(f.read())\n",
    "with open(\"exercises/en/country_text.txt\", encoding=\"utf8\") as f:\n",
    "    TEXT = f.read()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "patterns = list(nlp.pipe(COUNTRIES))\n",
    "matcher.add(\"COUNTRY\", patterns)\n",
    "\n",
    "# Create a doc and reset existing entities\n",
    "doc = nlp(TEXT)\n",
    "doc.ents = []\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matcher(doc):\n",
    "    # Create a Span with the label for \"GPE\"\n",
    "    span = Span(doc, start, end, label=\"GPE\")\n",
    "\n",
    "    # Overwrite the doc.ents and add the span\n",
    "    doc.ents = list(doc.ents) + [span]\n",
    "\n",
    "    # Get the span's root head token\n",
    "    span_root_head = span.root.head\n",
    "    # Print the text of the span root's head token and the span text\n",
    "    print(span_root_head.text, \"-->\", span.text)\n",
    "\n",
    "# Print the entities in the document\n",
    "print([(ent.text, ent.label_) for ent in doc.ents if ent.label_ == \"GPE\"])\n",
    "\n",
    "\n",
    "\n",
    "# In this exercise, you’ll be writing a custom component that uses the PhraseMatcher to find animal names in the document and\n",
    "# adds the matched spans to the doc.ents. A PhraseMatcher with the animal patterns has already been created as the variable matcher.\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "animals = [\"Golden Retriever\", \"cat\", \"turtle\", \"Rattus norvegicus\"]\n",
    "animal_patterns = list(nlp.pipe(animals))\n",
    "print(\"animal_patterns:\", animal_patterns)\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add(\"ANIMAL\", animal_patterns)\n",
    "\n",
    "# Define the custom component\n",
    "@Language.component(\"animal_component\")\n",
    "def animal_component_function(doc):\n",
    "    # Apply the matcher to the doc\n",
    "    matches = matcher(doc)\n",
    "    # Create a Span for each match and assign the label \"ANIMAL\"\n",
    "    spans = [Span(doc, start, end, label=\"ANIMAL\") for match_id, start, end in matches]\n",
    "    # Overwrite the doc.ents with the matched spans\n",
    "    doc.ents = spans\n",
    "    return doc\n",
    "\n",
    "\n",
    "# Add the component to the pipeline after the \"ner\" component\n",
    "nlp.add_pipe(\"animal_component\", after=\"ner\")\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Process the text and print the text and label for the doc.ents\n",
    "doc = nlp(\"I have a cat and a Golden Retriever\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# After creating the data for our corpus, we need to save it out to a .spacy file. The code from the previous example is already available.\n",
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, DocBin\n",
    "\n",
    "with open(\"exercises/en/iphone.json\", encoding=\"utf8\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add patterns to the matcher\n",
    "pattern1 = ([{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}])\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    doc.ents = spans\n",
    "    docs.append(doc)\n",
    "\n",
    "doc_bin = DocBin(docs=docs)\n",
    "doc_bin.to_disk(\"./train.spacy\")\n",
    "\n",
    "\n",
    "# The init config command auto-generates a config file for training with the default settings. We want to train a named entity recognizer, so we’ll generate a config file for one pipeline component, ner. Because we’re executing the command in a Jupyter environment in this course,\n",
    "#     we’re using the prefix !. If you’re running the command in your local terminal, you can leave this out.\n",
    "!python -m spacy init config ./config.cfg --lang en --pipeline ner\n",
    "\n",
    "\n",
    "# Let’s use the config file generated in the previous exercise and the training corpus we’ve created to train a named entity recognizer!\n",
    "\n",
    "# The train command lets you train a model from a training config file. A file config_gadget.cfg is already available in the directory exercises/en, as well as a file \n",
    "# train_gadget.spacy containing the training examples, and a file dev_gadget.spacy containing the evaluation examples. Because we’re executing the command in a Jupyter environment\n",
    "# in this course, we’re using the prefix !.\n",
    "# If you’re running the command in your local terminal, you can leave this out.\n",
    "!python -m spacy train ./exercises/en/config_gadget.cfg --output ./output --paths.train ./exercises/en/train_gadget.spacy --paths.dev ./exercises/en/dev_gadget.spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
